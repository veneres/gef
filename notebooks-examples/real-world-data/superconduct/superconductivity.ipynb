{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gamexplainer import GamExplainer\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import comb\n",
    "import pickle\n",
    "from sklearn.metrics import mean_squared_error\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O superconduct.zip https://archive.ics.uci.edu/ml/machine-learning-databases/00464/superconduct.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!unzip superconduct.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\", sep=\",\")\n",
    "train = df.head(int(len(df) * 0.7))\n",
    "test = df.tail(len(df) - len(train))\n",
    "resp_var = \"critical_temp\"\n",
    "X_train = train.drop(\"critical_temp\", axis=1)\n",
    "y_train = train[resp_var]\n",
    "X_test = test.drop(resp_var, axis=1)\n",
    "y_test = test[resp_var]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "lgbm_info = {}\n",
    "parameters = {\n",
    "    \"n_estimators\": np.geomspace(100, 10000, num=3, dtype=int),\n",
    "    \"num_leaves\": np.geomspace(32, 256, num=4, dtype=int),\n",
    "    \"learning_rate\": np.geomspace(1e-3, 1e-1, num=3)\n",
    "}\n",
    "CV_regressor = GridSearchCV(lgbm.LGBMRegressor(n_jobs=16), parameters, verbose=3, scoring=\"neg_root_mean_squared_error\")\n",
    "CV_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CV_regressor.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best params:\n",
    "{'learning_rate': 0.001, 'n_estimators': 10000, 'num_leaves': 64}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = lgbm.LGBMRegressor(learning_rate=0.001, n_estimators=10000, num_leaves=64, n_jobs=16, verbose=2)\n",
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(mean_squared_error(y_test, forest.predict(X_test), squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_splines = range(1, 11)\n",
    "range_n_inter = range(0, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\"verbose\": False,\n",
    "                      \"sample_method\": \"all\",\n",
    "                      \"inter_max_distance\": 64}\n",
    "\n",
    "acc = np.zeros((len(range_n_splines), len(range_n_inter)))\n",
    "for i, n_splines in enumerate(tqdm(range_n_splines)):\n",
    "    explanation_params[\"n_spline_terms\"] = n_splines\n",
    "    for j, n_inter in enumerate(range_n_inter):\n",
    "        if n_inter > comb(n_splines, 2):\n",
    "            continue\n",
    "        explanation_params[\"n_inter_terms\"] = n_inter\n",
    "        explainer = GamExplainer(**explanation_params)\n",
    "        gam = explainer.explain(forest, lam_search_space=[0.1, 1])\n",
    "\n",
    "        acc[i, j] = explainer.loss_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"feat_selection_superconduct\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or load it if already saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.load(\"feat_selection_superconduct.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results in a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = (len(range_n_splines), len(range_n_inter))\n",
    "mask = np.zeros(dimension)\n",
    "for i, n_splines in enumerate(tqdm(range_n_splines)):\n",
    "    for j, n_inter in enumerate(range_n_inter):\n",
    "        if n_inter > comb(n_splines, 2):\n",
    "            mask[i, j] = True \n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame(acc, columns=range_n_inter, index=range_n_splines)\n",
    "ax = sns.heatmap(accuracy_df, annot=True, mask = mask, cmap=sns.color_palette(\"Blues\", as_cmap=True), cbar_kws={'label': 'RMSE'})\n",
    "ax.set_xlabel(\"Number of interaction terms used\")\n",
    "ax.set_ylabel(\"Number of splines used\")\n",
    "file_out = \"splines_inter.pdf\"\n",
    "plt.savefig(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyze the maximum number of splits per feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\"verbose\": False,\n",
    "                      \"interaction_importance_method\":\"count_path\",\n",
    "                      \"feat_importance_method\": \"gain\",\n",
    "                      \"n_spline_terms\": 7,\n",
    "                      \"sample_method\": \"all\",\n",
    "                      \"n_spline_per_term\": 50,\n",
    "                      \"inter_max_distance\": 64,\n",
    "                      \"n_inter_terms\": 0,\n",
    "                      \"n_sample_gam\":int(1e5),\n",
    "                      \"portion_sample_test\":0.3,\n",
    "                      \"classification\": False\n",
    "                      }\n",
    "explainer = GamExplainer(**explanation_params)\n",
    "gam = explainer.explain(forest, lam_search_space=[0.1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in explainer.feature_dict.items():\n",
    "    if key in explainer.mif:\n",
    "        print(f\"{key}: {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_methods = [\"all\", \"quantile\", \"equal\", \"kmeans\", \"equi_size\"]\n",
    "range_m = range(50, 17000, 750)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampling_comparison.pickle', 'rb') as f:\n",
    "    acc_methods = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or compute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\"verbose\": False,\n",
    "                      \"interaction_importance_method\":\"count_path\",\n",
    "                      \"feat_importance_method\": \"gain\",\n",
    "                      \"n_spline_terms\": 7,\n",
    "                      \"n_spline_per_term\": 50,\n",
    "                      \"inter_max_distance\": 64,\n",
    "                      \"n_inter_terms\": 0,\n",
    "                      \"n_sample_gam\":int(1e5),\n",
    "                      \"portion_sample_test\":0.3,\n",
    "                      \"classification\": False\n",
    "                      }\n",
    "acc_methods = defaultdict(list)\n",
    "for m in tqdm(range_m):\n",
    "    explanation_params[\"sample_n\"] = m\n",
    "    for sampling_method in sampling_methods:\n",
    "        explanation_params[\"sample_method\"] = sampling_method\n",
    "        explainer = GamExplainer(**explanation_params)\n",
    "        gam = explainer.explain(forest, lam_search_space=[0.1, 1])\n",
    "\n",
    "        acc_methods[sampling_method].append(explainer.loss_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampling_comparison.pickle', 'wb') as f:\n",
    "    pickle.dump(acc_methods, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r\"\\emph{All-Thresholds}\", r\"\\emph{Quantile}\", r\"\\emph{Equi-Width}\", r\"\\emph{$k$-Means}\", \"\\emph{Equi-Size}\"]\n",
    "colors = sns.color_palette(n_colors=len(sampling_methods))\n",
    "for i, sampling_method in enumerate(sampling_methods):\n",
    "    plt.plot(range_m, acc_methods[sampling_method], 'o--', color=colors[i], label=labels[i])\n",
    "plt.xlabel(\"$K$\")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.legend()\n",
    "file_out = \"sampling_comparison.pdf\"\n",
    "plt.savefig(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splines investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\n",
    "                      \"verbose\": False,\n",
    "                      \"interaction_importance_method\":\"count_path\",\n",
    "                      \"feat_importance_method\": \"gain\",\n",
    "                      \"n_spline_terms\": 7,\n",
    "                      \"sample_method\": \"equi_size\",\n",
    "                      \"sample_n\": 4500,\n",
    "                      \"n_spline_per_term\": 50,\n",
    "                      \"inter_max_distance\": 64,\n",
    "                      \"n_inter_terms\": 0,\n",
    "                      \"n_sample_gam\":int(1e5),\n",
    "                      \"portion_sample_test\":0.3,\n",
    "                      \"classification\": False\n",
    "                      }\n",
    "explainer = GamExplainer(**explanation_params)\n",
    "explainer.explain(forest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With sample highlighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_display = {i: feat for i, feat in enumerate(X_train.columns)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.columns[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names_display[6] = \"WEAM\"\n",
    "feature_names_display[62] = \"WMTC\"\n",
    "feature_names_display[70] = \"WSTC\"\n",
    "feature_names_display[76] = \"WEV\"\n",
    "feature_names_display[74] = \"WGV\"\n",
    "feature_names_display[9] = \"SAM\"\n",
    "feature_names_display[33] = \"GMD\"\n",
    "feature_names_display[64] = \"WGTC\"\n",
    "feature_names_display[44] = \"WGEA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "sample = X_train.iloc[sample_index].values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 2, 3\n",
    "\n",
    "fig = plt.figure(figsize=(13, 10), tight_layout=False)\n",
    "\n",
    "lines = []\n",
    "\n",
    "terms = [(i, x) for i, x in enumerate(explainer.gam.terms) if not x.isintercept and not x.istensor]\n",
    "terms.sort(key=lambda x: x[1].feature)\n",
    "c1, c2, c3 = sns.color_palette(n_colors=3)\n",
    "\n",
    "plot_index = 0\n",
    "axes = []\n",
    "for i, term in enumerate(explainer.gam.terms):\n",
    "    if i == 6:\n",
    "        break\n",
    "    if term.isintercept or term.istensor:\n",
    "        continue\n",
    "    \n",
    "    ax = fig.add_subplot(n_row, n_col, plot_index + 1, sharey = axes[-1] if plot_index % n_col != 0 else None)\n",
    "\n",
    "    plt.setp(ax.get_yticklabels(), visible=plot_index % n_col == 0)\n",
    "    \n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "        \n",
    "    \n",
    "    # Spline print\n",
    "    grid = explainer.gam.generate_X_grid(term=i, meshgrid=term.istensor)\n",
    "    pdep, confi = explainer.gam.partial_dependence(term=i, X=grid, width=0.95, meshgrid=term.istensor)\n",
    "  \n",
    "    conf_u = ax.plot(grid[:, term.feature], confi[:,0], ls=\"--\", c=c2, zorder=1)\n",
    "    conf_l = ax.plot(grid[:, term.feature], confi[:,1], label=\"95% width confidence interval\", ls=\"--\", c=c2, zorder=1)\n",
    "    l1 = ax.plot(grid[:, term.feature], pdep, label=\"Spline learned\", lw=2, c=c1, zorder=2)\n",
    "    ax.set_title(feature_names_display[term.feature])\n",
    "    \n",
    "    \n",
    "    # Print the sample\n",
    "    x_point = sample[0, term.feature] # col vector\n",
    "    y_point = explainer.gam.partial_dependence(term=i, X=sample)\n",
    "    \n",
    "    plt.vlines(x_point, ax.get_ylim()[0], y_point, linestyle=\"dashed\", color=\"black\")\n",
    "    plt.hlines(y_point, ax.get_xlim()[0], x_point, linestyle=\"dashed\", color=\"black\")\n",
    "    ax.scatter(x_point, y_point, label=\"Sample under investigation\", color=\"black\", zorder=3)\n",
    "    \n",
    "    \n",
    "    plot_index +=1\n",
    "    axes.append(ax)\n",
    "\n",
    "\n",
    "#plt.subplots_adjust(hspace=0.3)\n",
    "file_out = \"generators.pdf\"\n",
    "\n",
    "params = {'legend.fontsize': 18,\n",
    "          'figure.figsize': (20, 5),\n",
    "          'axes.titlesize': 18,\n",
    "          'xtick.labelsize': 18,\n",
    "          'ytick.labelsize': 18}\n",
    "plt.rcParams.update(params)\n",
    "\n",
    "file_out = \"generators.pdf\"\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(-0.7, 2.5), ncol=3)\n",
    "plt.savefig(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shapley_values_training.pickle', 'rb') as f:\n",
    "    shap_values = pickle.load(f)\n",
    "with open('shap_explainer_training.pickle', 'rb') as f:\n",
    "    shap_explainer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or compute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap_explainer = shap.Explainer(forest)\n",
    "shap_values = shap_explainer(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shapley_values_training.pickle', 'wb') as f:\n",
    "    pickle.dump(shap_values, f)\n",
    "with open('shap_explainer_training.pickle', 'wb') as f:\n",
    "    pickle.dump(shap_explainer, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.plots.beeswarm(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation\n",
    "shap.plots.force(shap_explainer.expected_value, shap_values.values[0,:], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap_values[:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 2, 3\n",
    "\n",
    "fig = plt.figure(figsize=(13, 10))\n",
    "\n",
    "lines = []\n",
    "\n",
    "terms = [(i, x) for i, x in enumerate(explainer.gam.terms) if not x.isintercept and not x.istensor]\n",
    "terms.sort(key=lambda x: x[1].feature)\n",
    "c1, c2, c3 = sns.color_palette(n_colors=3)\n",
    "\n",
    "plot_index = 0\n",
    "axes = []\n",
    "for i, term in enumerate(explainer.gam.terms):\n",
    "    if i == 6:\n",
    "        break\n",
    "    if term.isintercept or term.istensor:\n",
    "        continue\n",
    "    \n",
    "    ax = fig.add_subplot(n_row, n_col, plot_index + 1, sharey = axes[-1] if plot_index % n_col != 0 else None)\n",
    "    \n",
    "    # Shap scatter print\n",
    "    shap.plots.scatter(shap_values[:,term.feature], ax=ax, show=False, hist=False, color=c1)\n",
    "    shap_plot = ax\n",
    "    \n",
    "    plt.setp(ax.get_yticklabels(), visible=plot_index % n_col == 0)\n",
    "    \n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.tick_params(labelsize=18)\n",
    "    ax.set_title(feature_names_display[term.feature])\n",
    "    \n",
    "    # Print the sample\n",
    "    x_point = shap_values[sample_index, term.feature].data\n",
    "    y_point = shap_values[sample_index, term.feature].values\n",
    "    \n",
    "    plt.vlines(x_point, ax.get_ylim()[0], y_point, linestyle=\"dashed\", color=\"black\")\n",
    "    plt.hlines(y_point, ax.get_xlim()[0], x_point, linestyle=\"dashed\", color=\"black\")\n",
    "    sample_plot = ax.scatter(x_point, y_point, label=\"Sample under investigation\", color=\"black\", zorder=3)\n",
    "\n",
    "    plot_index +=1\n",
    "    axes.append(ax)\n",
    "\n",
    "params = {'legend.fontsize': 18,\n",
    "          'figure.figsize': (20, 5),\n",
    "          'axes.titlesize': 18}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "#plt.subplots_adjust(hspace=0.3)\n",
    "file_out = \"shap.pdf\"\n",
    "dummy_shap_plot = Line2D([0], [0], marker='o', color=c1, label='SHAP values', lw=0)\n",
    "plt.legend(handles = [dummy_shap_plot, sample_plot], loc='upper center', bbox_to_anchor=(-1.47, 2.5), ncol=3, fontsize=14)\n",
    "plt.savefig(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feature_names = [feature_names_display.get(i, feat) for i, feat in enumerate(X_train.columns)]\n",
    "shap_values.feature_names = new_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "shap.plots.waterfall(shap_values[sample_index], max_display=7, show=False)\n",
    "plt.rcParams.update({'font.size': 14})\n",
    "plt.tight_layout()\n",
    "file_out = \"local_explain_shap.pdf\"\n",
    "plt.savefig(file_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gamexplainer.utils import plot_local_all_terms\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_local_all_terms(explainer.gam, feature_names_display, X_train.values, sample_index, range_perc = 20, figsize=(9, 15))\n",
    "file_out = \"local_explain_gef.pdf\"\n",
    "plt.savefig(file_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gamexplainer",
   "language": "python",
   "name": "gamexplainer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}