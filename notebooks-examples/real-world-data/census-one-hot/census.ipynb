{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightgbm as lgbm\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import seaborn as sns\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gamexplainer import GamExplainer\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from math import comb\n",
    "from sklearn.inspection import plot_partial_dependence\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O adult.csv https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "col_names = [\"age\", \"workclass\", \"fnlwgt\", \"education\", \"education-num\", \"marital-status\", \"occupation\", \"relationship\",\n",
    "             \"race\", \"sex\", \"capital-gain\", \"capital-loss\", \"hours-per-week\", \"native-country\", \"class\"]\n",
    "df = pd.read_csv(\"adult.csv\", sep=\",\", header=None, names=col_names, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df.head(int(len(df) * 0.7))\n",
    "test = df.tail(len(df) - len(train))\n",
    "resp_var = \"class\"\n",
    "X_train = train.drop(resp_var, axis=1)\n",
    "y_train = train[resp_var]\n",
    "X_test = test.drop(resp_var, axis=1)\n",
    "y_test = test[resp_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "final_cols = []\n",
    "categorical_feats = [\"workclass\", \"marital-status\", \"occupation\", \"relationship\", \"race\", \"sex\", \"native-country\"]\n",
    "to_drop = [\"education\"]\n",
    "transformers = []\n",
    "for column in X_train.columns:\n",
    "    name = column\n",
    "    trans = \"passthrough\"\n",
    "    if column in categorical_feats:\n",
    "        trans = OneHotEncoder()\n",
    "        name = f\"{column}_class\"\n",
    "    elif column in to_drop:\n",
    "        trans = \"drop\"\n",
    "    \n",
    "    transformers.append((name, trans, [f\"{column}\"]))\n",
    "    \n",
    "    if trans != \"drop\":\n",
    "        final_cols.append(column)\n",
    "ct = ColumnTransformer(transformers, remainder=\"passthrough\")\n",
    "ct.fit(X_train)\n",
    "# Encoder for the labels\n",
    "le = LabelEncoder()\n",
    "le.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "X_train_trans = ct.transform(X_train)\n",
    "X_test_trans = ct.transform(X_test)\n",
    "y_train_trans = le.transform(y_train)\n",
    "y_test_trans = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct.get_feature_names_out(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_trans.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_info = {}\n",
    "parameters = {\n",
    "    \"n_estimators\": np.geomspace(100, 10000, num=3, dtype=int),\n",
    "    \"num_leaves\": np.geomspace(32, 256, num=4, dtype=int),\n",
    "    \"learning_rate\": np.geomspace(1e-3, 1e-1, num=3)\n",
    "}\n",
    "CV_classifier = GridSearchCV(lgbm.LGBMClassifier(n_jobs=16), parameters, verbose=3, scoring=\"accuracy\")\n",
    "CV_classifier.fit(X_train_trans, y_train_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CV_classifier.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Best params:\n",
    "{'learning_rate': 0.01, 'n_estimators': 1000, 'num_leaves': 32}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = lgbm.LGBMClassifier(learning_rate=0.01, n_estimators=1000, num_leaves=32, verbose=2)\n",
    "forest.fit(X_train_trans, y_train_trans)\n",
    "forest_to_explain = forest.booster_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "print(accuracy_score(y_test_trans, forest.predict(X_test_trans)))\n",
    "print(classification_report(y_test_trans, forest.predict(X_test_trans)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_n_splines = range(1, 11)\n",
    "range_n_inter = range(0, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the numpy array "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\"verbose\": False,\n",
    "                      \"sample_method\": \"all\",\n",
    "                      \"classification\": True,\n",
    "                      \"inter_max_distance\": 32}\n",
    "\n",
    "acc = np.zeros((len(range_n_splines), len(range_n_inter)))\n",
    "for i, n_splines in enumerate(range_n_splines):\n",
    "    explanation_params[\"n_spline_terms\"] = n_splines\n",
    "    for j, n_inter in enumerate(range_n_inter):\n",
    "        if n_inter > comb(n_splines, 2):\n",
    "            continue\n",
    "        explanation_params[\"n_inter_terms\"] = n_inter\n",
    "        explainer = GamExplainer(**explanation_params)\n",
    "        gam = explainer.explain(forest_to_explain, lam_search_space=[0.1, 1])\n",
    "        print(f\"Fit {n_splines=}, {n_inter=} completed\")\n",
    "        acc[i, j] = explainer.loss_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"feat_selection\", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or load it if already saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = np.load(\"feat_selection.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results in a heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = (len(range_n_splines), len(range_n_inter))\n",
    "mask = np.zeros(dimension)\n",
    "for i, n_splines in enumerate(tqdm(range_n_splines)):\n",
    "    for j, n_inter in enumerate(range_n_inter):\n",
    "        if n_inter > comb(n_splines, 2):\n",
    "            mask[i, j] = True\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_df = pd.DataFrame(acc, columns=range_n_inter, index=range_n_splines)\n",
    "ax = sns.heatmap(accuracy_df, annot=True, mask=mask, cmap=sns.color_palette(\"Blues\", as_cmap=True),\n",
    "                 cbar_kws={'label': 'accuarcy'})\n",
    "ax.set_xlabel(\"Number of interaction terms used\")\n",
    "ax.set_ylabel(\"Number of splines used\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling strategy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the range to analyze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\"verbose\": False,\n",
    "                      \"interaction_importance_method\":\"count_path\",\n",
    "                      \"feat_importance_method\": \"gain\",\n",
    "                      \"n_spline_terms\": 6,\n",
    "                      \"sample_method\": \"all\",\n",
    "                      \"n_spline_per_term\": 50,\n",
    "                      \"inter_max_distance\": 32,\n",
    "                      \"n_inter_terms\": 0,\n",
    "                      \"n_sample_gam\":int(1e5),\n",
    "                      \"portion_sample_test\":0.3,\n",
    "                      \"classification\": True\n",
    "                      }\n",
    "explainer = GamExplainer(**explanation_params)\n",
    "gam = explainer.explain(forest, lam_search_space=[0.1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in explainer.feature_dict.items():\n",
    "    if key in explainer.mif:\n",
    "        print(f\"{key}: {len(value)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_methods = [\"all\", \"quantile\", \"equal\", \"kmeans\", \"equi_size\"]\n",
    "range_m = range(50, 5001, 250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\"verbose\": False,\n",
    "                      \"interaction_importance_method\":\"count_path\",\n",
    "                      \"feat_importance_method\": \"gain\",\n",
    "                      \"n_spline_terms\": 4,\n",
    "                      \"sample_method\": \"all\",\n",
    "                      \"n_spline_per_term\": 50,\n",
    "                      \"inter_max_distance\": 64,\n",
    "                      \"n_inter_terms\": 0,\n",
    "                      \"n_sample_gam\":int(1e5),\n",
    "                      \"portion_sample_test\":0.3,\n",
    "                      \"classification\": True\n",
    "                      }\n",
    "acc_methods = defaultdict(list)\n",
    "for m in tqdm(range_m):\n",
    "    explanation_params[\"sample_n\"] = m\n",
    "    for sampling_method in sampling_methods:\n",
    "        explanation_params[\"sample_method\"] = sampling_method\n",
    "        explainer = GamExplainer(**explanation_params)\n",
    "        gam = explainer.explain(forest_to_explain, lam_search_space=[0.1, 1])\n",
    "\n",
    "        acc_methods[sampling_method].append(explainer.loss_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampling_comparison.pickle', 'wb') as f:\n",
    "    pickle.dump(acc_methods, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or load it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('sampling_comparison.pickle', 'rb') as f:\n",
    "    acc_methods = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [r\"\\emph{All-Thresholds}\", r\"\\emph{Quantile}\", r\"\\emph{Equi-Width}\", r\"\\emph{$k$-Means}\", \"\\emph{Equi-Size}\"]\n",
    "colors = sns.color_palette(n_colors=len(sampling_methods))\n",
    "for i, sampling_method in enumerate(sampling_methods):\n",
    "    plt.plot(range_m, acc_methods[sampling_method], 'o--', color=colors[i], label=labels[i])\n",
    "plt.xlabel(\"$K$\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splines investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explanation_params = {\"verbose\": False,\n",
    "                      \"interaction_importance_method\":\"count_path\",\n",
    "                      \"feat_importance_method\": \"gain\",\n",
    "                      \"n_spline_terms\": 5,\n",
    "                      \"sample_method\": \"equi_size\",\n",
    "                      \"sample_n\": 2000,\n",
    "                      \"sample_method\": \"all\",\n",
    "                      \"n_spline_per_term\": 50,\n",
    "                      \"inter_max_distance\": 64,\n",
    "                      \"n_inter_terms\": 1,\n",
    "                      \"n_sample_gam\":int(1e5),\n",
    "                      \"portion_sample_test\":0.3,\n",
    "                      \"classification\": True\n",
    "                      }\n",
    "explainer = GamExplainer(**explanation_params)\n",
    "explainer.explain(forest_to_explain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With sample highlighting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = ct.get_feature_names_out().copy()\n",
    "final_cols[14] = \"MS-Married\"\n",
    "final_cols[47] = \"CapitalGain\"\n",
    "final_cols[11] = \"EducationNum\"\n",
    "final_cols[0] = \"Age\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_index = 0\n",
    "sample = X_train_trans[sample_index].reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_row, n_col = 2, 2\n",
    "\n",
    "fig = plt.figure(figsize=(13, 8), tight_layout=False)\n",
    "\n",
    "lines = []\n",
    "\n",
    "terms = [(i, x) for i, x in enumerate(explainer.gam.terms) if not x.isintercept and not x.istensor]\n",
    "terms.sort(key=lambda x: x[1].feature)\n",
    "c1, c2, c3 = sns.color_palette(n_colors=3)\n",
    "\n",
    "plot_index = 0\n",
    "axes = []\n",
    "for i, term in enumerate(explainer.gam.terms):\n",
    "    if plot_index == 4:\n",
    "        break\n",
    "    if term.isintercept or term.istensor:\n",
    "        continue\n",
    "\n",
    "    ax = fig.add_subplot(n_row, n_col, plot_index + 1, sharey = axes[-1] if plot_index % n_col != 0 else None)\n",
    "    plt.setp(ax.get_yticklabels(), visible=plot_index % n_col == 0)\n",
    "\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    print(term.feature)\n",
    "\n",
    "    # Spline print\n",
    "    grid = explainer.gam.generate_X_grid(term=i, meshgrid=term.istensor)\n",
    "    pdep, confi = explainer.gam.partial_dependence(term=i, X=grid, width=0.95, meshgrid=term.istensor)\n",
    "\n",
    "    conf_u = ax.plot(grid[:, term.feature], confi[:, 0], ls=\"--\", c=c2, zorder=1)\n",
    "    conf_l = ax.plot(grid[:, term.feature], confi[:, 1], label=\"95% width confidence interval\", ls=\"--\", c=c2, zorder=1)\n",
    "    l1 = ax.plot(grid[:, term.feature], pdep, label=\"Spline learned\", lw=2, c=c1, zorder=2)\n",
    "    ax.set_title(final_cols[term.feature])\n",
    "\n",
    "    # Print the sample\n",
    "    \"\"\"\n",
    "    x_point = sample[0, term.feature]  # col vector\n",
    "    y_point = explainer.gam.partial_dependence(term=i, X=sample)\n",
    "\n",
    "    plt.vlines(x_point, ax.get_ylim()[0], y_point, linestyle=\"dashed\", color=c3)\n",
    "    plt.hlines(y_point, ax.get_xlim()[0], x_point, linestyle=\"dashed\", color=c3)\n",
    "    ax.scatter(x_point, y_point, label=\"Sample under investigation\", color=c3, zorder=3)\n",
    "    \"\"\"\n",
    "\n",
    "    plot_index += 1\n",
    "    axes.append(ax)\n",
    "\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "file_out = \"generators.pdf\"\n",
    "params = {'legend.fontsize': 18,\n",
    "          'figure.figsize': (20, 5),\n",
    "          'axes.titlesize': 18,\n",
    "          'xtick.labelsize': 18,\n",
    "          'ytick.labelsize': 18}\n",
    "plt.rcParams.update(params)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(-0.35, 2.7), ncol=3)\n",
    "plt.savefig(file_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results with SHAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('shapley_values_training.pickle', 'rb') as f:\n",
    "    shap_values = pickle.load(f)\n",
    "with open('shap_explainer_training.pickle', 'rb') as f:\n",
    "    shap_explainer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or compute them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "shap_explainer = shap.Explainer(forest, feature_names=final_cols)\n",
    "shap_values = shap_explainer(X_train_trans.toarray())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the first prediction's explanation\n",
    "shap.plots.force(shap_explainer.expected_value[1], shap_values.values[0, :, 1], matplotlib=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = shap_values[:, :, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "n_row, n_col = 2, 2\n",
    "\n",
    "fig = plt.figure(figsize=(13, 8))\n",
    "\n",
    "lines = []\n",
    "\n",
    "terms = [(i, x) for i, x in enumerate(explainer.gam.terms) if not x.isintercept and not x.istensor]\n",
    "terms.sort(key=lambda x: x[1].feature)\n",
    "c1, c2, c3 = sns.color_palette(n_colors=3)\n",
    "\n",
    "plot_index = 0\n",
    "axes = []\n",
    "for i, term in enumerate(explainer.gam.terms):\n",
    "    if plot_index == 4:\n",
    "        break\n",
    "    if term.isintercept or term.istensor:\n",
    "        continue\n",
    "\n",
    "    ax = fig.add_subplot(n_row, n_col, plot_index + 1, sharey = axes[-1] if plot_index % n_col != 0 else None)\n",
    "\n",
    "    # Shap scatter print\n",
    "    shap.plots.scatter(shap_values[:, term.feature], ax=ax, show=False, hist=False, color=c1)\n",
    "    shap_plot = ax\n",
    "    \n",
    "    plt.setp(ax.get_yticklabels(), visible=plot_index % n_col == 0)\n",
    "    ax.tick_params(labelsize=18)\n",
    "\n",
    "    ax.set_ylabel(\"\")\n",
    "    ax.set_xlabel(\"\")\n",
    "    ax.set_title(final_cols[term.feature])\n",
    "\n",
    "    # Print the sample\n",
    "    \"\"\"\n",
    "    x_point = shap_values[sample_index, term.feature].data\n",
    "    y_point = shap_values[sample_index, term.feature].values\n",
    "\n",
    "    plt.vlines(x_point, ax.get_ylim()[0], y_point, linestyle=\"dashed\", color=c2)\n",
    "    plt.hlines(y_point, ax.get_xlim()[0], x_point, linestyle=\"dashed\", color=c2)\n",
    "    sample_plot = ax.scatter(x_point, y_point, label=\"Sample under investigation\", color=c2, zorder=3)\n",
    "    \"\"\"\n",
    "\n",
    "    plot_index += 1\n",
    "    axes.append(ax)\n",
    "    \n",
    "params = {'legend.fontsize': 18,\n",
    "          'figure.figsize': (20, 5),\n",
    "          'axes.titlesize': 18}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "plt.subplots_adjust(hspace=0.3)\n",
    "file_out = \"shap.pdf\"\n",
    "dummy_shap_plot = Line2D([0], [0], marker='o', color=c1, label='SHAP values', lw=0)\n",
    "plt.legend(handles=[dummy_shap_plot], loc='upper center', bbox_to_anchor=(-1.0, 2.7), ncol=3, fontsize=14)\n",
    "plt.savefig(file_out)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gamexplainer",
   "language": "python",
   "name": "gamexplainer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}